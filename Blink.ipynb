{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "c60SLzUQE0YC",
    "outputId": "3ecb6377-f796-44ed-edb0-105d4a36e347"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WmsuufODIyQ5"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wavfB_-WEev0"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Activation, Conv2D, Flatten, Dense, MaxPooling2D # CNN.\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator # Use data augmentation.\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wLJ2fFD7I5tZ"
   },
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "LXiE5X-yFW7k",
    "outputId": "725d709f-ef64-4503-bb19-3d52c6ad764b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2586, 26, 34, 1) (2586, 1)\n",
      "(288, 26, 34, 1) (288, 1)\n"
     ]
    }
   ],
   "source": [
    "# Use a dataset that has already been created.\n",
    "x_train = np.load('Data/x_train.npy').astype(np.float32)\n",
    "y_train = np.load('Data/y_train.npy').astype(np.float32)\n",
    "x_val = np.load('Data/x_val.npy').astype(np.float32)\n",
    "y_val = np.load('Data/y_val.npy').astype(np.float32)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vmyKDSdBJR6C"
   },
   "source": [
    "### Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "r5WzbTBDHukW",
    "outputId": "e0f9ab93-0e68-457a-d413-de78fa4e33e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13911f250>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(3, 1, 1)\n",
    "plt.title(str(y_train[0]))\n",
    "plt.imshow(x_train[0].reshape((26, 34)), cmap='gray')\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title(str(y_val[4]))\n",
    "plt.imshow(x_val[4].reshape((26, 34)), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pYitl39TJ1bL"
   },
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P9o6qly2JQ79"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, # 0~255사이의 이미지를 0~1사이로 바꿈.\n",
    "    rotation_range=10, # 이미지를 +-10도 회전.\n",
    "    width_shift_range=0.2, # 가로 크기 변형.\n",
    "    height_shift_range=0.2, # 세로 크기 변형.\n",
    "    shear_range=0.2 # 이미지를 비틈.\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    x=x_train, y=y_train,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow(\n",
    "    x=x_val, y=y_val,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ONkXn5OkL503"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "colab_type": "code",
    "id": "jgKeUyUCLwxz",
    "outputId": "ce724bb3-4e26-483f-c359-9a24f355c2d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 26, 34, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 34, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 17, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               786944    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(26, 34, 1)) # 세로 26, 가로 34인 gray-scale 이미지를 input으로 사용.\n",
    "\n",
    "# 커널 수만 32, 64, 128 순으로 3번 변경 진행.\n",
    "net = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(inputs)\n",
    "net = MaxPooling2D(pool_size=2)(net) # 차원축소를 위해 Maxpooling2D 사용.\n",
    "\n",
    "net = Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = Flatten()(net) # convolution layer를 1차원으로 길게 펼침.\n",
    "\n",
    "net = Dense(512)(net) # Dense layer로 512개의 Fully connected layer를 연결.\n",
    "net = Activation('relu')(net)\n",
    "net = Dense(1)(net) # 0~1사이의 값으로 출력하기 위해 필요.\n",
    "outputs = Activation('sigmoid')(net) # sigmoid 함수로 0~1사의 값을 가지도록 함.\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# adam optimizer를 사용하고, 0, 1을 판단하는 것이기에 loss는 binary_crossentropy를 사용.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pAUQ-KMhNGJy",
    "outputId": "258c9a1a-5e6b-4e54-d96f-6bb9c0041ff8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "81/81 [==============================] - 3s 40ms/step - loss: 0.4802 - acc: 0.7753 - val_loss: 0.3569 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.86806, saving model to Model/2020_03_19_15_51_42.h5\n",
      "Epoch 2/50\n",
      "81/81 [==============================] - 3s 36ms/step - loss: 0.2658 - acc: 0.8921 - val_loss: 0.1458 - val_acc: 0.9618\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.86806 to 0.96181, saving model to Model/2020_03_19_15_51_42.h5\n",
      "Epoch 3/50\n",
      "81/81 [==============================] - 3s 37ms/step - loss: 0.1678 - acc: 0.9374 - val_loss: 0.1250 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.96181 to 0.96875, saving model to Model/2020_03_19_15_51_42.h5\n",
      "Epoch 4/50\n",
      "81/81 [==============================] - 3s 39ms/step - loss: 0.1180 - acc: 0.9590 - val_loss: 0.2121 - val_acc: 0.9618\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.96875\n",
      "Epoch 5/50\n",
      "81/81 [==============================] - 3s 39ms/step - loss: 0.1178 - acc: 0.9582 - val_loss: 0.0667 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.96875 to 0.98264, saving model to Model/2020_03_19_15_51_42.h5\n",
      "Epoch 6/50\n",
      "81/81 [==============================] - 3s 40ms/step - loss: 0.0956 - acc: 0.9683 - val_loss: 0.0693 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.98264\n",
      "Epoch 7/50\n",
      "81/81 [==============================] - 3s 38ms/step - loss: 0.0730 - acc: 0.9776 - val_loss: 0.0939 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.98264\n",
      "Epoch 8/50\n",
      "81/81 [==============================] - 3s 37ms/step - loss: 0.0677 - acc: 0.9768 - val_loss: 0.0442 - val_acc: 0.9896\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.98264 to 0.98958, saving model to Model/2020_03_19_15_51_42.h5\n",
      "Epoch 9/50\n",
      "81/81 [==============================] - 3s 40ms/step - loss: 0.0689 - acc: 0.9795 - val_loss: 0.0380 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.98958\n",
      "Epoch 10/50\n",
      "81/81 [==============================] - 3s 38ms/step - loss: 0.0769 - acc: 0.9760 - val_loss: 0.0608 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.98958\n",
      "Epoch 11/50\n",
      "81/81 [==============================] - 3s 40ms/step - loss: 0.0626 - acc: 0.9791 - val_loss: 0.0206 - val_acc: 0.9896\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.98958\n",
      "Epoch 12/50\n",
      "81/81 [==============================] - 3s 38ms/step - loss: 0.0527 - acc: 0.9830 - val_loss: 0.0263 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.98958\n",
      "Epoch 13/50\n",
      "81/81 [==============================] - 3s 37ms/step - loss: 0.0510 - acc: 0.9838 - val_loss: 0.0181 - val_acc: 0.9896\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98958\n",
      "Epoch 14/50\n",
      "81/81 [==============================] - 3s 38ms/step - loss: 0.0411 - acc: 0.9884 - val_loss: 0.0357 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.98958 to 0.99306, saving model to Model/2020_03_19_15_51_42.h5\n",
      "Epoch 15/50\n",
      "81/81 [==============================] - 3s 40ms/step - loss: 0.0476 - acc: 0.9869 - val_loss: 0.0400 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99306\n",
      "Epoch 16/50\n",
      "81/81 [==============================] - 3s 42ms/step - loss: 0.0280 - acc: 0.9907 - val_loss: 0.0317 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.99306 to 0.99653, saving model to Model/2020_03_19_15_51_42.h5\n",
      "Epoch 17/50\n",
      "81/81 [==============================] - 4s 44ms/step - loss: 0.0486 - acc: 0.9834 - val_loss: 0.0221 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99653\n",
      "Epoch 18/50\n",
      "81/81 [==============================] - 3s 40ms/step - loss: 0.0365 - acc: 0.9903 - val_loss: 0.0156 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99653\n",
      "Epoch 19/50\n",
      "81/81 [==============================] - 3s 39ms/step - loss: 0.0450 - acc: 0.9876 - val_loss: 0.0260 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99653\n",
      "Epoch 20/50\n",
      "81/81 [==============================] - 3s 41ms/step - loss: 0.0244 - acc: 0.9938 - val_loss: 0.0157 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99653\n",
      "Epoch 21/50\n",
      "81/81 [==============================] - 4s 45ms/step - loss: 0.0292 - acc: 0.9903 - val_loss: 0.0318 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99653\n",
      "Epoch 22/50\n",
      "81/81 [==============================] - 4s 44ms/step - loss: 0.0357 - acc: 0.9884 - val_loss: 0.0158 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99653\n",
      "Epoch 23/50\n",
      "81/81 [==============================] - 3s 38ms/step - loss: 0.0221 - acc: 0.9934 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.99653 to 1.00000, saving model to Model/2020_03_19_15_51_42.h5\n",
      "Epoch 24/50\n",
      "81/81 [==============================] - 3s 39ms/step - loss: 0.0199 - acc: 0.9930 - val_loss: 0.0095 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 1.00000\n",
      "Epoch 25/50\n",
      "81/81 [==============================] - 3s 39ms/step - loss: 0.0218 - acc: 0.9915 - val_loss: 0.0146 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 1.00000\n",
      "Epoch 26/50\n",
      "81/81 [==============================] - 3s 42ms/step - loss: 0.0316 - acc: 0.9903 - val_loss: 0.0176 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 1.00000\n",
      "Epoch 27/50\n",
      "81/81 [==============================] - 3s 39ms/step - loss: 0.0169 - acc: 0.9930 - val_loss: 0.0293 - val_acc: 0.9896\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 1.00000\n",
      "Epoch 28/50\n",
      "81/81 [==============================] - 3s 41ms/step - loss: 0.0233 - acc: 0.9938 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 1.00000\n",
      "Epoch 29/50\n",
      "81/81 [==============================] - 4s 49ms/step - loss: 0.0150 - acc: 0.9954 - val_loss: 0.0420 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 1.00000\n",
      "Epoch 30/50\n",
      "81/81 [==============================] - 3s 37ms/step - loss: 0.0285 - acc: 0.9911 - val_loss: 0.0149 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 1.00000\n",
      "Epoch 31/50\n",
      "81/81 [==============================] - 3s 36ms/step - loss: 0.0243 - acc: 0.9915 - val_loss: 0.0169 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 1.00000\n",
      "Epoch 32/50\n",
      "81/81 [==============================] - 3s 36ms/step - loss: 0.0207 - acc: 0.9915 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 1.00000\n",
      "Epoch 33/50\n",
      "81/81 [==============================] - 3s 38ms/step - loss: 0.0189 - acc: 0.9957 - val_loss: 0.0049 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 34/50\n",
      "81/81 [==============================] - 3s 38ms/step - loss: 0.0137 - acc: 0.9954 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 1.00000\n",
      "Epoch 35/50\n",
      "81/81 [==============================] - 3s 38ms/step - loss: 0.0088 - acc: 0.9969 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 1.00000\n",
      "Epoch 36/50\n",
      "81/81 [==============================] - 3s 38ms/step - loss: 0.0078 - acc: 0.9969 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 1.00000\n",
      "Epoch 37/50\n",
      "81/81 [==============================] - 3s 38ms/step - loss: 0.0088 - acc: 0.9973 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 1.00000\n",
      "Epoch 38/50\n",
      "81/81 [==============================] - 3s 37ms/step - loss: 0.0097 - acc: 0.9977 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 1.00000\n",
      "Epoch 39/50\n",
      "81/81 [==============================] - 3s 38ms/step - loss: 0.0055 - acc: 0.9981 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 1.00000\n",
      "Epoch 40/50\n",
      "81/81 [==============================] - 3s 37ms/step - loss: 0.0046 - acc: 0.9992 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 1.00000\n",
      "Epoch 41/50\n",
      "81/81 [==============================] - 3s 38ms/step - loss: 0.0038 - acc: 0.9992 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 1.00000\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 3s 38ms/step - loss: 0.0041 - acc: 0.9988 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 1.00000\n",
      "Epoch 43/50\n",
      "81/81 [==============================] - 4s 49ms/step - loss: 0.0046 - acc: 0.9985 - val_loss: 8.8801e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 44/50\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0040 - acc: 0.9985 - val_loss: 9.6113e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 1.00000\n",
      "Epoch 45/50\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0042 - acc: 0.9985 - val_loss: 7.2060e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 1.00000\n",
      "Epoch 46/50\n",
      "81/81 [==============================] - 4s 44ms/step - loss: 0.0041 - acc: 0.9992 - val_loss: 9.4295e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 1.00000\n",
      "Epoch 47/50\n",
      "81/81 [==============================] - 4s 44ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 9.0341e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 1.00000\n",
      "Epoch 48/50\n",
      "81/81 [==============================] - 4s 43ms/step - loss: 0.0029 - acc: 0.9992 - val_loss: 8.9647e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 1.00000\n",
      "Epoch 49/50\n",
      "81/81 [==============================] - 4s 43ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 8.2808e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 1.00000\n",
      "Epoch 50/50\n",
      "81/81 [==============================] - 3s 43ms/step - loss: 0.0044 - acc: 0.9985 - val_loss: 5.3766e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 1.00000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x139966e50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator, epochs=50, validation_data=val_generator,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('Model/%s.h5' % (start_time), monitor='val_acc', save_best_only=True, mode='max', verbose=1), # 모델이 좋을 경우, 저장.\n",
    "        ReduceLROnPlateau(monitor='val_acc',factor=0.2, patience=10, verbose=1, mode='auto', min_lr=1e-05) # 학습이 잘 되지 않을 경우, learning_rate를 줄이도록 설정.\n",
    "    ]\n",
    ")\n",
    "# generator로 데이터를 불러온 경우에는 fit_generator로 학습시켜주는 것이 좋음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SoLe4RYuRJHU"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GHvuCzHnPK7H"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "5PLDASF6RUlB",
    "outputId": "5ceb9b4c-1185-40aa-b74f-d4a1529b7d1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13ab96d10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('Model/%s.h5' % (start_time)) # keras 모델을 로드.\n",
    "\n",
    "y_pred = model.predict(x_val/255.) # model.predict()_모델을 통해 데이터를 예측. 0~1사이로 바꾸었기 때문에 /255.\n",
    "y_pred_logical = (y_pred > 0.5).astype(np.int) \n",
    "# y_pred가 0.5보다 크면 눈을 뜬 이미지로 인식, 작으면 눈을 감은 이미지로 인식하도록. True면 눈을 뜬 것, False면 눈을 감은 것. 그리고 이걸 np.int를 통해 0과 1로 변환.(0은 감은 것, 1이면 눈을 뜬 것.)\n",
    "\n",
    "print('test acc: %s' % accuracy_score(y_val, y_pred_logical)) # accuracy_score()_테스트 결과 정확도를 계산.\n",
    "cm = confusion_matrix(y_val, y_pred_logical)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZwnlbIdvUxh_"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "91LIr8UlR1nQ"
   },
   "outputs": [],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cez1DKJQVDo4"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = (34, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "colab_type": "code",
    "id": "ievHIPBaVGU2",
    "outputId": "0f863c32-45e9-4326-aa33-05a0ed21ba7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 26, 34, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 34, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 17, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               786944    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('Data/shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "model = load_model('Model/2020_03_19_15_51_42.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zmUXSkfvVmig"
   },
   "outputs": [],
   "source": [
    "def crop_eye(img, eye_points):\n",
    "    x1, y1 = np.amin(eye_points, axis=0)\n",
    "    x2, y2 = np.amax(eye_points, axis=0)\n",
    "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "    w = (x2 - x1) * 1.2\n",
    "    h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "    margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "    min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "    max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "    eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "    eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "    return eye_img, eye_rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "-Oc-ONOrWmhM",
    "outputId": "7d4d0859-bbec-4def-c7de-96cae5fa5691"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Data/video.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img_ori = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "    img = img_ori.copy()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        shapes = predictor(gray, face)\n",
    "        shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "        eye_img_1, eye_rect_1 = crop_eye(gray, eye_points=shapes[36:42])\n",
    "        eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "        eye_img_1 = cv2.resize(eye_img_1, dsize=IMG_SIZE)\n",
    "        eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "        eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "        cv2.imshow('1', eye_img_1)\n",
    "        cv2.imshow('r', eye_img_r)\n",
    "\n",
    "        eye_input_1 = eye_img_1.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "        eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "        pred_1 = model.predict(eye_input_1)\n",
    "        pred_r = model.predict(eye_input_r)\n",
    "\n",
    "        state_1 = '0 %.1f' if pred_1 > 0.1 else '- %.1f'\n",
    "        state_r = '0 %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "        state_1 = state_1 % pred_1\n",
    "        state_r = state_r % pred_r\n",
    "\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_1[0:2]), pt2=tuple(eye_rect_1[2:4]), color=(255, 255, 255), thickness=2)\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255, 255, 255), thickness=2)\n",
    "\n",
    "        cv2.putText(img, state_1, tuple(eye_rect_1[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow('result', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Blink.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
