{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breast_Cancer_ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+GfJ7JmrBfAof7YwAHaNn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sa96102/Python_exam/blob/master/Breast_Cancer_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "213O2-CQIKll",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c01b0171-99c1-4099-a4a9-3197e53b1a29"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJAc_IDnH-96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split # 학습 데이터와 테스트 데이터를 분리할 때 사용.\n",
        "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict # Cross valdiation을 구현할 때 사용.\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk6kvPfpJZFR",
        "colab_type": "text"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yxCb3aBJX9K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "1ae85851-ef93-495d-c3e0-5521d1eb7c2d"
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Python_exam/Data/breast-cancer-wisconsin-data.csv')\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302         M  ...                  0.11890          NaN\n",
              "1    842517         M  ...                  0.08902          NaN\n",
              "2  84300903         M  ...                  0.08758          NaN\n",
              "3  84348301         M  ...                  0.17300          NaN\n",
              "4  84358402         M  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHs-X-K2JhPd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "outputId": "170056de-8bd4-4576-f1cc-e5b71a73f704"
      },
      "source": [
        "data.info() # 데이터의 타입과 null 개수를 출력."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 33 columns):\n",
            "id                         569 non-null int64\n",
            "diagnosis                  569 non-null object\n",
            "radius_mean                569 non-null float64\n",
            "texture_mean               569 non-null float64\n",
            "perimeter_mean             569 non-null float64\n",
            "area_mean                  569 non-null float64\n",
            "smoothness_mean            569 non-null float64\n",
            "compactness_mean           569 non-null float64\n",
            "concavity_mean             569 non-null float64\n",
            "concave points_mean        569 non-null float64\n",
            "symmetry_mean              569 non-null float64\n",
            "fractal_dimension_mean     569 non-null float64\n",
            "radius_se                  569 non-null float64\n",
            "texture_se                 569 non-null float64\n",
            "perimeter_se               569 non-null float64\n",
            "area_se                    569 non-null float64\n",
            "smoothness_se              569 non-null float64\n",
            "compactness_se             569 non-null float64\n",
            "concavity_se               569 non-null float64\n",
            "concave points_se          569 non-null float64\n",
            "symmetry_se                569 non-null float64\n",
            "fractal_dimension_se       569 non-null float64\n",
            "radius_worst               569 non-null float64\n",
            "texture_worst              569 non-null float64\n",
            "perimeter_worst            569 non-null float64\n",
            "area_worst                 569 non-null float64\n",
            "smoothness_worst           569 non-null float64\n",
            "compactness_worst          569 non-null float64\n",
            "concavity_worst            569 non-null float64\n",
            "concave points_worst       569 non-null float64\n",
            "symmetry_worst             569 non-null float64\n",
            "fractal_dimension_worst    569 non-null float64\n",
            "Unnamed: 32                0 non-null float64\n",
            "dtypes: float64(31), int64(1), object(1)\n",
            "memory usage: 146.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DraSl14cK7pv",
        "colab_type": "text"
      },
      "source": [
        "### Refine Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yq7TSxIKtYy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "6961d76b-31f3-4ea4-8db1-bb82b1b3d3ea"
      },
      "source": [
        "data.drop(['id', 'Unnamed: 32'], axis=1, inplace=True)\n",
        "\n",
        "# Benign : 양성(0)\n",
        "# Malignant : 음성 (1)\n",
        "\n",
        "data['diagnosis'] = data['diagnosis'].map({'B': 0, 'M': 1}) # df.map()_데이터프레임 안에서 값을 대치하고 싶을 때 사용. df.apply()는 좀 더 복잡한 연산을 할 때 사용.\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0          1        17.99  ...          0.4601                  0.11890\n",
              "1          1        20.57  ...          0.2750                  0.08902\n",
              "2          1        19.69  ...          0.3613                  0.08758\n",
              "3          1        11.42  ...          0.6638                  0.17300\n",
              "4          1        20.29  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELvCdtJkLWEP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "24d8e3c0-9439-4f53-e67f-0f3aa268a6b1"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.372583</td>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>0.405172</td>\n",
              "      <td>1.216853</td>\n",
              "      <td>2.866059</td>\n",
              "      <td>40.337079</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0.011796</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.483918</td>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.277313</td>\n",
              "      <td>0.551648</td>\n",
              "      <td>2.021855</td>\n",
              "      <td>45.491006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.017908</td>\n",
              "      <td>0.030186</td>\n",
              "      <td>0.006170</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.015160</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>1.108000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>24.530000</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.020450</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.478900</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>3.357000</td>\n",
              "      <td>45.190000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.042050</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>2.873000</td>\n",
              "      <td>4.885000</td>\n",
              "      <td>21.980000</td>\n",
              "      <td>542.200000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.078950</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "count  569.000000   569.000000  ...      569.000000               569.000000\n",
              "mean     0.372583    14.127292  ...        0.290076                 0.083946\n",
              "std      0.483918     3.524049  ...        0.061867                 0.018061\n",
              "min      0.000000     6.981000  ...        0.156500                 0.055040\n",
              "25%      0.000000    11.700000  ...        0.250400                 0.071460\n",
              "50%      0.000000    13.370000  ...        0.282200                 0.080040\n",
              "75%      1.000000    15.780000  ...        0.317900                 0.092080\n",
              "max      1.000000    28.110000  ...        0.663800                 0.207500\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7TAybUDMB2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "b0830719-8c0a-49a6-ecc3-3e5e27b276c3"
      },
      "source": [
        "sns.countplot(data['diagnosis']) # 데이터의 개수를 출력하는 그리프 그리기."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f500c3c7cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSJI6Q0GS1BkKkqTOUJAkdf8fjOSpHfLvWLEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP00CmR5MPaf",
        "colab_type": "text"
      },
      "source": [
        "### Split Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsU8_1z-MNMQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8939f87d-0e30-4f96-904a-03cbd867c41b"
      },
      "source": [
        "train, test = train_test_split(data, test_size=0.2, random_state=2019)\n",
        "\n",
        "x_train = train.drop(['diagnosis'], axis=1)\n",
        "y_train = train.diagnosis\n",
        "\n",
        "x_test = test.drop(['diagnosis'], axis=1)\n",
        "y_test = test.diagnosis\n",
        "\n",
        "print(len(train), len(test))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "455 114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjR3XUiBNjyg",
        "colab_type": "text"
      },
      "source": [
        "### SVM (Support Vector Machine)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtnXfKPuM0BJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c70b5f7f-21e3-42e3-eaba-eb6014e7eef9"
      },
      "source": [
        "model = svm.SVC(gamma='scale')\n",
        "model.fit(x_train, y_train) # svm로 학습.\n",
        "\n",
        "y_pred = model.predict(x_test) # 주어진 x값에 대해 y를 예측.\n",
        "\n",
        "print('SVM : %.2f' % (metrics.accuracy_score(y_pred, y_test) * 100))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM : 91.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_tgNE6tOuTC",
        "colab_type": "text"
      },
      "source": [
        "### Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VbxIyIgOrx0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d2015ae9-10cc-4ba1-b5c9-68d76a24a34e"
      },
      "source": [
        "model = DecisionTreeClassifier()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "print('DecisionTreeClassifier : %.2f' % (metrics.accuracy_score(y_pred, y_test) * 100))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier : 88.60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVN0ELNXQvPw",
        "colab_type": "text"
      },
      "source": [
        "### KNeighborsClassifier (KNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2NAoIkuQtoQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "47cb3ed9-e5ef-4e4e-a95d-f72f7b964243"
      },
      "source": [
        "model = KNeighborsClassifier()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "print('KNeighborsClassifier : %.2f' % (metrics.accuracy_score(y_pred, y_test) * 100))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier : 92.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F48asmylRD-z",
        "colab_type": "text"
      },
      "source": [
        "### LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0DKJCsXQ9vu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "baa6f3a3-b27b-40ac-d265-2caf930cf19e"
      },
      "source": [
        "model = LogisticRegression(solver='lbfgs', max_iter=2000)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "print('LogisticRegression : %.2f' % (metrics.accuracy_score(y_pred, y_test) * 100))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression : 94.74\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tcc8zbTLRW5b",
        "colab_type": "text"
      },
      "source": [
        "### RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iP6kSY6RS7A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fefd752f-f212-4c1c-daf4-d20f830b20b5"
      },
      "source": [
        "model = RandomForestClassifier(n_estimators=100)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "print('RandomForestClassifier : %.2f' % (metrics.accuracy_score(y_pred, y_test) * 100))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier : 92.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnmniB8URqTF",
        "colab_type": "text"
      },
      "source": [
        "### Compute Feature Importances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdYl6Ji8RhKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "719bf984-4dc6-4e4a-814e-fd3439f338f4"
      },
      "source": [
        "features = pd.Series(\n",
        "    model.feature_importances_, index=x_train.columns\n",
        ").sort_values(ascending=False) # model.feature_importances__모델을 예측하는데 있어 어떤 파라미터가 중요한지 계산.\n",
        "\n",
        "print(features)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "perimeter_worst            0.155639\n",
            "radius_worst               0.142576\n",
            "concave points_worst       0.126880\n",
            "area_worst                 0.101851\n",
            "concave points_mean        0.089636\n",
            "area_mean                  0.071441\n",
            "concavity_mean             0.052617\n",
            "perimeter_mean             0.048723\n",
            "concavity_worst            0.030034\n",
            "radius_mean                0.020848\n",
            "compactness_worst          0.016006\n",
            "area_se                    0.015780\n",
            "radius_se                  0.013517\n",
            "perimeter_se               0.013418\n",
            "texture_worst              0.011703\n",
            "texture_mean               0.011611\n",
            "smoothness_worst           0.010088\n",
            "symmetry_worst             0.009275\n",
            "fractal_dimension_worst    0.008462\n",
            "concave points_se          0.007080\n",
            "compactness_mean           0.005471\n",
            "smoothness_se              0.005423\n",
            "smoothness_mean            0.004650\n",
            "compactness_se             0.004647\n",
            "fractal_dimension_se       0.004203\n",
            "concavity_se               0.004111\n",
            "texture_se                 0.003914\n",
            "symmetry_mean              0.003658\n",
            "symmetry_se                0.003391\n",
            "fractal_dimension_mean     0.003351\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu3vDJyjSD31",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f40037fc-1c40-47a2-e359-100d612b9a22"
      },
      "source": [
        "top_5_features = features.keys()[:5]\n",
        "\n",
        "print(top_5_features)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['perimeter_worst', 'radius_worst', 'concave points_worst', 'area_worst',\n",
            "       'concave points_mean'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbhRAkAXS0EX",
        "colab_type": "text"
      },
      "source": [
        "### SVM (Top 5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYzjLr2hSuLm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0d4eb560-bf1e-4383-e87d-9b3b689175f7"
      },
      "source": [
        "model = svm.SVC(gamma='scale')\n",
        "model.fit(x_train[top_5_features], y_train)\n",
        "\n",
        "y_pred = model.predict(x_test[top_5_features])\n",
        "\n",
        "print('SVM(Top 5) : %.2f' % (metrics.accuracy_score(y_pred, y_test) * 100))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM(Top 5) : 91.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5-SquxQTBFR",
        "colab_type": "text"
      },
      "source": [
        "### Cross Validation (Tedious)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fqku92FFS-ZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "e37f0f00-151e-46c8-ee6c-182fc2f78249"
      },
      "source": [
        "model = svm.SVC(gamma='scale')\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=2019)\n",
        "\n",
        "accs = []\n",
        "\n",
        "for train_index, test_index in cv.split(data[top_5_features]):\n",
        "    x_train = data.iloc[train_index][top_5_features]\n",
        "    y_train = data.iloc[train_index].diagnosis\n",
        "\n",
        "    x_test = data.iloc[test_index][top_5_features]\n",
        "    y_test = data.iloc[test_index].diagnosis\n",
        "\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(x_test)\n",
        "\n",
        "    accs.append(metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(accs)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.7807017543859649, 0.8947368421052632, 0.9736842105263158, 0.9298245614035088, 0.9380530973451328]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnJW58J0Uwwh",
        "colab_type": "text"
      },
      "source": [
        "### Cross Validation (Simple)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW67r2WmUsKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "bd549ed7-9ccf-46c7-fb4a-b2ead753b785"
      },
      "source": [
        "model = svm.SVC(gamma='scale')\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=2019)\n",
        "\n",
        "accs = cross_val_score(model, data[top_5_features], data.diagnosis, cv=cv) # Cross Validation을 적용, 학습한 후 모델의 점수를 출력.\n",
        "\n",
        "print(accs)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.78070175 0.89473684 0.97368421 0.92982456 0.9380531 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aIKIve_VC1n",
        "colab_type": "text"
      },
      "source": [
        "### Test All Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kb5NNu6VBqk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "d7b0d444-6d5d-49f9-e5db-98a8a24c3be2"
      },
      "source": [
        "models = {\n",
        "    'SVM' : svm.SVC(gamma='scale'),\n",
        "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
        "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
        "    'LogisticRegression': LogisticRegression(solver='lbfgs', max_iter=2000),\n",
        "    'RandomForestClassifier': RandomForestClassifier(n_estimators=100)\n",
        "}\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=2019)\n",
        "\n",
        "for name, model in models.items():\n",
        "    scores = cross_val_score(model, data[top_5_features], data.diagnosis, cv=cv)\n",
        "\n",
        "    print('%s : %.2f%%' % (name, np.mean(scores) * 100))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM : 90.34%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier : 91.74%\n",
            "KNeighborsClassifier : 88.40%\n",
            "LogisticRegression : 90.69%\n",
            "RandomForestClassifier : 93.50%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMePvP48WOqo",
        "colab_type": "text"
      },
      "source": [
        "### Normalize Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz9PXpvPV6Wz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNMjoKpgWUB0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "b329f010-eed0-4670-f6da-ddaf7867fee0"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1)) # MinMaxScaler()_데이터를 표준화. cv2.normalize()와 같음.\n",
        "scaled_data = scaler.fit_transform(data[top_5_features])\n",
        "\n",
        "models = {\n",
        "    'SVM' : svm.SVC(gamma='scale'),\n",
        "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
        "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
        "    'LogisticRegression': LogisticRegression(solver='lbfgs', max_iter=2000),\n",
        "    'RandomForestClassifier': RandomForestClassifier(n_estimators=100)\n",
        "}\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=2019)\n",
        "\n",
        "for name, model in models.items():\n",
        "    scores = cross_val_score(model, data[top_5_features], data.diagnosis, cv=cv)\n",
        "\n",
        "    print('%s : %.2f%%' % (name, np.mean(scores) * 100))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM : 90.34%\n",
            "DecisionTreeClassifier : 91.56%\n",
            "KNeighborsClassifier : 88.40%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression : 90.69%\n",
            "RandomForestClassifier : 93.50%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}